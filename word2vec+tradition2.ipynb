{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "## import packages\n",
    "########################################\n",
    "%matplotlib inline\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "import codecs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk import word_tokenize\n",
    "from string import punctuation\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation,  Bidirectional\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "import gc\n",
    "import seaborn as sns\n",
    "from snownlp import SnowNLP\n",
    "from collections import Counter\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "import cPickle\n",
    "import gensim\n",
    "import math\n",
    "from fuzzywuzzy import fuzz\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import skew, kurtosis\n",
    "from scipy.spatial.distance import cosine, cityblock, jaccard, canberra, euclidean, minkowski, braycurtis\n",
    "\n",
    "\n",
    "import sys\n",
    "stdout = sys.stdout\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf-8')\n",
    "sys.stdout = stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "## set directories and parameters\n",
    "########################################\n",
    "BASE_DIR = 'data/'\n",
    "EMBEDDING_FILE = BASE_DIR + 'GoogleNews-vectors-negative300.bin'\n",
    "TRAIN_DATA_FILE = BASE_DIR + 'cor_train.csv'\n",
    "TEST_DATA_FILE = BASE_DIR + 'cor_test.csv'\n",
    "MAX_SEQUENCE_LENGTH = 30\n",
    "MAX_NB_WORDS = 200000\n",
    "EMBEDDING_DIM = 300\n",
    "VALIDATION_SPLIT = 0.02\n",
    "\n",
    "num_lstm = np.random.randint(175, 275)\n",
    "num_dense = np.random.randint(100, 150)\n",
    "rate_drop_lstm = 0.15 + np.random.rand() * 0.25\n",
    "rate_drop_dense = 0.15 + np.random.rand() * 0.25\n",
    "\n",
    "act = 'relu'\n",
    "re_weight = True # whether to re-weight classes to fit the 17.5% share in test set\n",
    "\n",
    "STAMP = 'lstm_%d_%d_%.2f_%.2f'%(num_lstm, num_dense, rate_drop_lstm, \\\n",
    "        rate_drop_dense)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 开始计算 glove 特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text dataset\n"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "## process texts in datasets\n",
    "########################################\n",
    "print('Processing text dataset')\n",
    "\n",
    "# The function \"text_to_wordlist\" is from\n",
    "# https://www.kaggle.com/currie32/quora-question-pairs/the-importance-of-cleaning-text\n",
    "def text_to_wordlist(text, remove_stopwords=False, stem_words=False):\n",
    "    # Clean the text, with the option to remove stopwords and to stem words.\n",
    "    \n",
    "    # Convert words to lower case and split them\n",
    "    text = text.lower().split()\n",
    "\n",
    "    # Optionally, remove stop words\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        text = [w for w in text if not w in stops]\n",
    "    \n",
    "    text = \" \".join(text)\n",
    "\n",
    "    # Clean the text\n",
    "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\",\", \" \", text)\n",
    "    text = re.sub(r\"\\.\", \" \", text)\n",
    "    text = re.sub(r\"!\", \" ! \", text)\n",
    "    text = re.sub(r\"\\/\", \" \", text)\n",
    "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
    "    text = re.sub(r\"\\+\", \" + \", text)\n",
    "    text = re.sub(r\"\\-\", \" - \", text)\n",
    "    text = re.sub(r\"\\=\", \" = \", text)\n",
    "    text = re.sub(r\"'\", \" \", text)\n",
    "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
    "    text = re.sub(r\":\", \" : \", text)\n",
    "    text = re.sub(r\" e g \", \" eg \", text)\n",
    "    text = re.sub(r\" b g \", \" bg \", text)\n",
    "    text = re.sub(r\" u s \", \" american \", text)\n",
    "    text = re.sub(r\"\\0s\", \"0\", text)\n",
    "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
    "    text = re.sub(r\"e - mail\", \"email\", text)\n",
    "    text = re.sub(r\"j k\", \"jk\", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "    \n",
    "    # Optionally, shorten words to their stems\n",
    "    if stem_words:\n",
    "        text = text.split()\n",
    "        stemmer = SnowballStemmer('english')\n",
    "        stemmed_words = [stemmer.stem(word) for word in text]\n",
    "        text = \" \".join(stemmed_words)\n",
    "    \n",
    "    # Return a list of words\n",
    "    return(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 404290 texts in train.csv\n",
      "Found 2345796 texts in test.csv\n",
      "Found 120500 unique tokens\n"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "## text to sequence numbers\n",
    "########################################\n",
    "train_1 = [] \n",
    "train_2 = []\n",
    "labels = []\n",
    "with codecs.open(TRAIN_DATA_FILE, encoding='utf-8') as f:\n",
    "    reader = csv.reader(f, delimiter=',')\n",
    "    header = next(reader)\n",
    "    for values in reader:\n",
    "        train_1.append(text_to_wordlist(values[3]))\n",
    "        train_2.append(text_to_wordlist(values[4]))\n",
    "        labels.append(int(values[5]))\n",
    "print('Found %s texts in train.csv' % len(train_1))\n",
    "\n",
    "test_1 = []\n",
    "test_2 = []\n",
    "test_ids = []\n",
    "with codecs.open(TEST_DATA_FILE, encoding='utf-8') as f:\n",
    "    reader = csv.reader(f, delimiter=',')\n",
    "    header = next(reader)\n",
    "    for values in reader:\n",
    "        test_1.append(text_to_wordlist(values[1]))\n",
    "        test_2.append(text_to_wordlist(values[2]))\n",
    "        test_ids.append(values[0])\n",
    "print('Found %s texts in test.csv' % len(test_1))\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(train_1 + train_2 + test_1 + test_2)\n",
    "\n",
    "sequences_1 = tokenizer.texts_to_sequences(train_1)\n",
    "sequences_2 = tokenizer.texts_to_sequences(train_2)\n",
    "test_sequences_1 = tokenizer.texts_to_sequences(test_1)\n",
    "test_sequences_2 = tokenizer.texts_to_sequences(test_2)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens' % len(word_index))\n",
    "\n",
    "data_1 = pad_sequences(sequences_1, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "data_2 = pad_sequences(sequences_2, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "\n",
    "labels = np.array(labels)\n",
    "\n",
    "test_data_1 = pad_sequences(test_sequences_1, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "test_data_2 = pad_sequences(test_sequences_2, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "test_ids = np.array(test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Shape of data tensor:', (404290, 30))\n",
      "('Shape of label tensor:', (404290, 30))\n",
      "('Shape of data tensor:', (2345796, 30))\n",
      "('Shape of label tensor:', (2345796, 30))\n",
      "('Shape of label tensor:', (404290,))\n",
      "finish\n"
     ]
    }
   ],
   "source": [
    "print('Shape of data tensor:', data_1.shape)\n",
    "print('Shape of label tensor:', data_2.shape)\n",
    "print('Shape of data tensor:', test_data_1.shape)\n",
    "print('Shape of label tensor:', test_data_2.shape)\n",
    "print('Shape of label tensor:', labels.shape)\n",
    "\n",
    "np.savetxt(\"data/data_1.csv\", data_1, delimiter=\",\")\n",
    "np.savetxt(\"data/data_2.csv\", data_2, delimiter=\",\")\n",
    "np.savetxt(\"data/test_data_1.csv\", test_data_1, delimiter=\",\")\n",
    "np.savetxt(\"data/test_data_2.csv\", test_data_2, delimiter=\",\")\n",
    "np.savetxt(\"data/labels.csv\", labels, delimiter=\",\")\n",
    "\n",
    "print 'finish'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing word vectors\n",
      "Found 3000000 word vectors of word2vec\n"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "## index word vectors\n",
    "########################################\n",
    "print('Indexing word vectors')\n",
    "\n",
    "word2vec = KeyedVectors.load_word2vec_format(EMBEDDING_FILE, \\\n",
    "        binary=True)\n",
    "print('Found %s word vectors of word2vec' % len(word2vec.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing embedding matrix\n",
      "Null word embeddings: 61789\n"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "## prepare embeddings\n",
    "########################################\n",
    "print('Preparing embedding matrix')\n",
    "\n",
    "nb_words = min(MAX_NB_WORDS, len(word_index))+1\n",
    "\n",
    "embedding_matrix = np.zeros((nb_words, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    if word in word2vec.vocab:\n",
    "        embedding_matrix[i] = word2vec.word_vec(word)\n",
    "print('Null word embeddings: %d' % np.sum(np.sum(embedding_matrix, axis=1) == 0))\n",
    "\n",
    "np.save('data/embedding_matrix.npy',embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_1 = np.loadtxt(\"data/data_1.csv\", delimiter=\",\")\n",
    "data_2 = np.loadtxt(\"data/data_2.csv\", delimiter=\",\")\n",
    "test_data_1 = np.loadtxt(\"data/test_data_1.csv\", delimiter=\",\")\n",
    "test_data_2 = np.loadtxt(\"data/test_data_2.csv\", delimiter=\",\")\n",
    "labels = np.loadtxt(\"data/labels.csv\", delimiter=\",\")\n",
    "embedding_matrix = np.load('data/embedding_matrix.npy')\n",
    "nb_words = 120501"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 开始计算传统特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "## traditional features processing\n",
    "########################################\n",
    "\n",
    "train=pd.read_csv(TRAIN_DATA_FILE)\n",
    "test=pd.read_csv(TEST_DATA_FILE)\n",
    "\n",
    "train_qs=pd.Series(train['question1'].tolist()+\n",
    "                   train['question2'].tolist()).astype(str)\n",
    "\n",
    "test_qs=pd.Series(test['question1'].tolist()+\n",
    "                  test['question2'].tolist()).astype(str)\n",
    "\n",
    "stops=set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "## traditional features function\n",
    "########################################\n",
    "\n",
    "#计算两句话的共有词\n",
    "def word_match_share(row):\n",
    "    q1words={}\n",
    "    q2words={}\n",
    "    for word in str(row['question1']).lower().split():\n",
    "        if word not in stops:#如果不是stopwords则存入q1words=>(key,value)\n",
    "            q1words[word]=1\n",
    "    for word in str(row['question2']).lower().split():\n",
    "        if word not in stops:\n",
    "            q2words[word]=1\n",
    "    if len(q1words)==0 or len(q2words)==0:\n",
    "        return 0\n",
    "    shared_words_q1=[w for w in q1words.keys() if w in q2words]\n",
    "    shared_words_q2=[w for w in q2words.keys() if w in q1words]\n",
    "    R=(len(shared_words_q1)+len(shared_words_q2)+0.0)/(len(q1words)+len(q2words))\n",
    "    return R\n",
    "\n",
    "def get_weight(count,eps=10000,min_count=2):\n",
    "    if count<min_count:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1.0/(count+eps)\n",
    "    \n",
    "def tfidf_word_match_share(row):\n",
    "    q1words = {}\n",
    "    q2words = {}\n",
    "    for word in str(row['question1']).lower().split():\n",
    "        if word not in stops:\n",
    "            q1words[word] = 1\n",
    "    for word in str(row['question2']).lower().split():\n",
    "        if word not in stops:\n",
    "            q2words[word] = 1\n",
    "    if len(q1words) == 0 or len(q2words) == 0:\n",
    "        # The computer-generated chaff includes a few questions that are nothing but stopwords\n",
    "        return 0\n",
    "    \n",
    "    shared_weights = [weights.get(w, 0) for w in q1words.keys() if w in q2words] + \\\n",
    "                    [weights.get(w, 0) for w in q2words.keys() if w in q1words]\n",
    "    total_weights = [weights.get(w, 0) for w in q1words] + [weights.get(w, 0) for w in q2words]\n",
    "        \n",
    "    R = (np.sum(shared_weights)+0.0) / np.sum(total_weights)\n",
    "    return R\n",
    "\n",
    "def sentence_sentiment_diff(row):\n",
    "    s1=SnowNLP(str(row['question1'])).sentiments\n",
    "    s2=SnowNLP(str(row['question2'])).sentiments\n",
    "    return (s1-s2)*(s1-s2)\n",
    "\n",
    "words=(\" \".join(train_qs)).lower().split()\n",
    "counts=Counter(words)\n",
    "weights={word:get_weight(count) for word,count in counts.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 如果已经保存特征，那么下面就不用执行了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = pd.DataFrame()\n",
    "x_test = pd.DataFrame()\n",
    "\n",
    "x_train['word_match'] = train.apply(word_match_share,axis=1,raw=True)\n",
    "x_test['word_match'] = test.apply(word_match_share, axis=1, raw=True)\n",
    "x_train['tfidf_word_match'] = train.apply(tfidf_word_match_share, axis=1, raw=True)\n",
    "x_test['tfidf_word_match'] = test.apply(tfidf_word_match_share,axis=1,raw=True)\n",
    "x_train['sentiment']=train.apply(sentence_sentiment_diff,axis=1,raw=True)\n",
    "x_test['sentiment']=test.apply(sentence_sentiment_diff,axis=1,raw=True)\n",
    "\n",
    "len_q1=train.question1.apply(lambda x: len(str(x)))\n",
    "len_q2=train.question2.apply(lambda x: len(str(x)))\n",
    "x_train['diff_len'] = abs(len_q1-len_q2)\n",
    "\n",
    "len_char_q1=train.question1.apply(lambda x: len(''.join(set(str(x).replace(' ', '')))))\n",
    "len_char_q2=train.question2.apply(lambda x: len(''.join(set(str(x).replace(' ', '')))))\n",
    "x_train['diff_len_char']=abs(len_char_q1-len_char_q2)\n",
    "\n",
    "len_word_q1=train.question1.apply(lambda x: len(str(x).split()))\n",
    "len_word_q2=train.question2.apply(lambda x: len(str(x).split()))\n",
    "x_train['diff_len_word']=abs(len_word_q1-len_word_q2)\n",
    "\n",
    "len_q1=test.question1.apply(lambda x: len(str(x)))\n",
    "len_q2=test.question2.apply(lambda x: len(str(x)))\n",
    "x_test['diff_len'] = abs(len_q1-len_q2)\n",
    "\n",
    "len_char_q1=test.question1.apply(lambda x: len(''.join(set(str(x).replace(' ', '')))))\n",
    "len_char_q2=test.question2.apply(lambda x: len(''.join(set(str(x).replace(' ', '')))))\n",
    "x_test['diff_len_char']=abs(len_char_q1-len_char_q2)\n",
    "\n",
    "len_word_q1=test.question1.apply(lambda x: len(str(x).split()))\n",
    "len_word_q2=test.question2.apply(lambda x: len(str(x).split()))\n",
    "x_test['diff_len_word']=abs(len_word_q1-len_word_q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = train[['question1']].copy()\n",
    "df2 = train[['question2']].copy()\n",
    "df1_test = test[['question1']].copy()\n",
    "df2_test = test[['question2']].copy()\n",
    "\n",
    "df2.rename(columns = {'question2':'question1'},inplace=True)\n",
    "df2_test.rename(columns = {'question2':'question1'},inplace=True)\n",
    "\n",
    "train_questions = df1.append(df2)\n",
    "train_questions = train_questions.append(df1_test)\n",
    "train_questions = train_questions.append(df2_test)\n",
    "\n",
    "print 'origin train_questions length:'\n",
    "\n",
    "print len(train_questions)\n",
    "\n",
    "#drop duplicated questions in train_questions\n",
    "train_questions.drop_duplicates(subset = ['question1'],inplace=True)\n",
    "\n",
    "print 'after remove duplicates length:'\n",
    "\n",
    "print len(train_questions)\n",
    "\n",
    "#reset index of train_questions\n",
    "train_questions.reset_index(inplace=True,drop=True)\n",
    "\n",
    "#construct new Series (index,question)\n",
    "questions_dict = pd.Series(train_questions.index.values,index=train_questions.question1.values).to_dict()\n",
    "\n",
    "train_cp = train.copy()\n",
    "test_cp = test.copy()\n",
    "\n",
    "train_cp.drop(['qid1','qid2'],axis=1,inplace=True)\n",
    "\n",
    "test_cp['is_duplicate'] = -1\n",
    "test_cp.rename(columns={'test_id':'id'},inplace=True)\n",
    "\n",
    "comb = pd.concat([train_cp,test_cp])\n",
    "\n",
    "\n",
    "comb['q1_hash'] = comb['question1'].map(questions_dict)\n",
    "comb['q2_hash'] = comb['question2'].map(questions_dict)\n",
    "\n",
    "q1_vc = comb.q1_hash.value_counts().to_dict()\n",
    "q2_vc = comb.q2_hash.value_counts().to_dict()\n",
    "\n",
    "def try_apply_dict(x,dict_to_apply):\n",
    "    try:\n",
    "        return dict_to_apply[x]\n",
    "    except KeyError:\n",
    "        return 0\n",
    "#map to frequency space\n",
    "comb['q1_freq'] = comb['q1_hash'].map(lambda x: try_apply_dict(x,q1_vc) + try_apply_dict(x,q2_vc))\n",
    "comb['q2_freq'] = comb['q2_hash'].map(lambda x: try_apply_dict(x,q1_vc) + try_apply_dict(x,q2_vc))\n",
    "\n",
    "train_comb = comb[comb['is_duplicate'] >= 0][['id','q1_hash','q2_hash','q1_freq','q2_freq','is_duplicate']]\n",
    "test_comb = comb[comb['is_duplicate'] < 0][['id','q1_hash','q2_hash','q1_freq','q2_freq']]\n",
    "\n",
    "x_train['q1_freq']=train_comb['q1_freq']\n",
    "x_train['q2_freq']=train_comb['q2_freq']\n",
    "\n",
    "x_test['q1_freq']=test_comb['q1_freq']\n",
    "x_test['q2_freq']=test_comb['q2_freq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train.to_pickle('data/x_train.pkl')\n",
    "x_test.to_pickle('data/x_test.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 直接调用保存好的 feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_hand_features = pd.read_pickle('data/x_train.pkl')\n",
    "test_hand_features = pd.read_pickle('data/x_test.pkl')\n",
    "x_train = train_hand_features[['word_match','tfidf_word_match','sentiment','diff_len','diff_len_char','diff_len_word','q1_freq','q2_freq']]\n",
    "x_test = test_hand_features[['word_match','tfidf_word_match','sentiment','diff_len','diff_len_char','diff_len_word','q1_freq','q2_freq']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 新特征：句子关联句子\n",
    "interdict_train=pd.read_csv('interdict_train.csv',index_col=0)\n",
    "interdict_test=pd.read_csv('interdict_test.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 新特征：各种句子之间的距离\n",
    "dis_train=pd.read_csv('data/trainset_dis.csv')\n",
    "dis_test=pd.read_csv('data/testset_dis.csv')\n",
    "fuzz_train=pd.read_csv('data/fuzz_train.csv')\n",
    "fuzz_test=pd.read_csv('data/fuzz_test.csv')\n",
    "x_train = pd.concat([x_train, dis_train, fuzz_train, interdict_train], axis=1)\n",
    "x_test = pd.concat([x_test, dis_test, fuzz_test, interdict_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print x_train.shape, x_test.shape, dis_train.shape, dis_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 数据归一化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data_columns = x_train.columns\n",
    "x_train = x_train.fillna(0)\n",
    "x_test = x_test.fillna(0)\n",
    "\n",
    "ss = StandardScaler()\n",
    "ss.fit(np.vstack((x_train, x_test)))\n",
    "x_train = ss.transform(x_train)\n",
    "x_test = ss.transform(x_test)\n",
    "\n",
    "x_train = pd.DataFrame(data=x_train, columns=data_columns)\n",
    "x_test = pd.DataFrame(data=x_test, columns=data_columns)\n",
    "\n",
    "x_train.to_pickle('data/x_train_norm.pkl')\n",
    "x_test.to_pickle('data/x_test_norm.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = pd.read_pickle('data/x_train_norm.pkl')\n",
    "x_test = pd.read_pickle('data/x_test_norm.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "## sample train/validation data\n",
    "########################################\n",
    "\n",
    "np.random.seed(1234)\n",
    "perm = np.random.permutation(len(data_1))\n",
    "idx_train = perm[:int(len(data_1)*(1-VALIDATION_SPLIT))]\n",
    "idx_val = perm[int(len(data_1)*(1-VALIDATION_SPLIT)):]\n",
    "\n",
    "data_1_train = np.vstack((data_1[idx_train], data_2[idx_train]))\n",
    "data_2_train = np.vstack((data_2[idx_train], data_1[idx_train]))\n",
    "\n",
    "data_1_val = np.vstack((data_1[idx_val], data_2[idx_val]))\n",
    "data_2_val = np.vstack((data_2[idx_val], data_1[idx_val]))\n",
    "\n",
    "data_3_train = np.vstack((x_train.values[idx_train],x_train.values[idx_train]))\n",
    "data_3_val = np.vstack((x_train.values[idx_val],x_train.values[idx_val]))\n",
    "\n",
    "labels_train = np.concatenate((labels[idx_train], labels[idx_train]))\n",
    "labels_val = np.concatenate((labels[idx_val], labels[idx_val]))\n",
    "\n",
    "\n",
    "weight_val = np.ones(len(labels_val))\n",
    "\n",
    "if re_weight:\n",
    "    weight_val *= 0.472001959\n",
    "    weight_val[labels_val==0] = 1.309028344\n",
    "    class_weight = {0: 1.309028344, 1: 0.472001959}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_lstm = 225\n",
    "num_dense = 140\n",
    "rate_drop_lstm = 0.37\n",
    "rate_drop_dense = 0.16\n",
    "\n",
    "STAMP = 'lstm_%d_%d_%.2f_%.2f'%(num_lstm, num_dense, rate_drop_lstm, \\\n",
    "        rate_drop_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "## define the model structure\n",
    "########################################\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"4\"\n",
    "\n",
    "embedding_layer = Embedding(nb_words,\n",
    "        EMBEDDING_DIM,\n",
    "        weights=[embedding_matrix],\n",
    "        input_length=MAX_SEQUENCE_LENGTH,\n",
    "        trainable=False)\n",
    "lstm_layer =  Bidirectional(LSTM(num_lstm, dropout=rate_drop_lstm, recurrent_dropout=rate_drop_lstm))\n",
    "\n",
    "sequence_1_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedded_sequences_1 = embedding_layer(sequence_1_input)\n",
    "x1 = lstm_layer(embedded_sequences_1)\n",
    "\n",
    "sequence_2_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedded_sequences_2 = embedding_layer(sequence_2_input)\n",
    "y1 = lstm_layer(embedded_sequences_2)\n",
    "\n",
    "z1 = Input(shape=(x_train.shape[1],), dtype='float32')\n",
    "z1_dense = Dense(num_dense/2, activation=act)(z1)\n",
    "\n",
    "merged = concatenate([x1, y1, z1_dense])\n",
    "merged = BatchNormalization()(merged)\n",
    "merged = Dropout(rate_drop_dense)(merged)\n",
    "\n",
    "merged = Dense(num_dense, activation=act)(merged)\n",
    "merged = BatchNormalization()(merged)\n",
    "merged = Dropout(rate_drop_dense)(merged)\n",
    "\n",
    "preds = Dense(1, activation='sigmoid')(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lstm_225_140_0.37_0.16\n",
      "Train on 792408 samples, validate on 16172 samples\n",
      "Epoch 1/200\n",
      "792408/792408 [==============================] - 218s - loss: 0.2366 - acc: 0.8294 - val_loss: 0.2041 - val_acc: 0.8454\n",
      "Epoch 2/200\n",
      "792408/792408 [==============================] - 217s - loss: 0.1949 - acc: 0.8562 - val_loss: 0.1935 - val_acc: 0.8679\n",
      "Epoch 3/200\n",
      "792408/792408 [==============================] - 218s - loss: 0.1849 - acc: 0.8639 - val_loss: 0.1838 - val_acc: 0.8611\n",
      "Epoch 4/200\n",
      "792408/792408 [==============================] - 219s - loss: 0.1767 - acc: 0.8711 - val_loss: 0.1822 - val_acc: 0.8668\n",
      "Epoch 5/200\n",
      "792408/792408 [==============================] - 219s - loss: 0.1703 - acc: 0.8759 - val_loss: 0.1790 - val_acc: 0.8770\n",
      "Epoch 6/200\n",
      "792408/792408 [==============================] - 219s - loss: 0.1644 - acc: 0.8806 - val_loss: 0.1740 - val_acc: 0.8681\n",
      "Epoch 7/200\n",
      "792408/792408 [==============================] - 219s - loss: 0.1597 - acc: 0.8845 - val_loss: 0.1712 - val_acc: 0.8816\n",
      "Epoch 8/200\n",
      "792408/792408 [==============================] - 218s - loss: 0.1549 - acc: 0.8883 - val_loss: 0.1726 - val_acc: 0.8881\n",
      "Epoch 9/200\n",
      "792408/792408 [==============================] - 218s - loss: 0.1507 - acc: 0.8919 - val_loss: 0.1724 - val_acc: 0.8902\n",
      "Epoch 10/200\n",
      "792408/792408 [==============================] - 220s - loss: 0.1465 - acc: 0.8953 - val_loss: 0.1699 - val_acc: 0.8853\n",
      "Epoch 11/200\n",
      "792408/792408 [==============================] - 218s - loss: 0.1424 - acc: 0.8984 - val_loss: 0.1790 - val_acc: 0.8936\n",
      "Epoch 12/200\n",
      "792408/792408 [==============================] - 218s - loss: 0.1395 - acc: 0.9008 - val_loss: 0.1711 - val_acc: 0.8936\n",
      "Epoch 13/200\n",
      "792408/792408 [==============================] - 218s - loss: 0.1360 - acc: 0.9037 - val_loss: 0.1744 - val_acc: 0.8888\n",
      "Epoch 14/200\n",
      "792408/792408 [==============================] - 218s - loss: 0.1337 - acc: 0.9059 - val_loss: 0.1771 - val_acc: 0.8894\n"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "## train the model\n",
    "########################################\n",
    "model = Model(inputs=[sequence_1_input, sequence_2_input, z1], \\\n",
    "        outputs=preds)\n",
    "# model.load_weights(bst_model_path)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "        optimizer='nadam',\n",
    "        metrics=['acc'])\n",
    "#model.summary()\n",
    "print(STAMP)\n",
    "\n",
    "early_stopping =EarlyStopping(monitor='val_loss', patience=3)\n",
    "bst_model_path = STAMP + '.h5'\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(bst_model_path, monitor='val_loss',save_best_only=True, save_weights_only=True)\n",
    "# model.load_weights(bst_model_path)\n",
    "hist = model.fit([data_1_train, data_2_train, data_3_train], labels_train, \\\n",
    "        validation_data=([data_1_val, data_2_val, data_3_val], labels_val, weight_val), \\\n",
    "        epochs=200, batch_size=2048, shuffle=True, \\\n",
    "        class_weight=class_weight, callbacks=[early_stopping, model_checkpoint])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAFBCAYAAABuEzZyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqIuIiGTE/w9qUKQ8HGJpqQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f688ad9df90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = pd.DataFrame({'epoch': [ i + 1 for i in hist.epoch ],\n",
    "                    'training': hist.history['acc'],\n",
    "                    'validation': hist.history['val_acc'],\n",
    "                    'loss': hist.history['loss'],\n",
    "                   'val_loss': hist.history['val_loss']})\n",
    "ax = acc.ix[:,:].plot(x='epoch', figsize={5,8}, grid=True)\n",
    "ax.set_ylabel(\"accuracy\")\n",
    "ax.set_ylim([0.0,1.0]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2345796/2345796 [==============================] - 224s   \n",
      "2345796/2345796 [==============================] - 223s   \n"
     ]
    }
   ],
   "source": [
    "bst_val_score = min(hist.history['val_loss'])\n",
    "\n",
    "########################################\n",
    "## make the submission\n",
    "########################################\n",
    "model.load_weights(bst_model_path)\n",
    "\n",
    "preds = model.predict([test_data_1, test_data_2, x_test.values], batch_size=5000, verbose=1)\n",
    "preds += model.predict([test_data_2, test_data_1, x_test.values], batch_size=5000, verbose=1)\n",
    "preds /= 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_ids = np.arange(len(preds))\n",
    "submission = pd.DataFrame({'test_id':test_ids, 'is_duplicate':preds.ravel()})\n",
    "submission.to_csv('%.4f_'%(bst_val_score)+STAMP+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "a = 'helloworld'\n",
    "print len(set(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
